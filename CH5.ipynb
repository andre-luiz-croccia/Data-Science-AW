{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e17c6e8-f294-4c6b-a215-86a35cf44d66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install xgboost lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "040e164b-db14-48a4-bdff-a850dd6530cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# ETAPA 1 -CRIA√á√ÉO DA TABELA DE PREVIS√ÉO DE PRODUTO E LOJA\n",
    "# =========================\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, LongType, StringType\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# Carregar dados agregados por produto + loja + m√™s\n",
    "# =========================\n",
    "df_vendas = spark.table(\"ted_dev.dbt_acroccia_aw_marts.fato_pedidos_2\")\n",
    "\n",
    "# Criar coluna ano_mes e converter para date\n",
    "df_vendas = df_vendas.withColumn(\"ano_mes\", F.date_format(\"data_de_venda\", \"yyyy-MM\"))\n",
    "df_agg = df_vendas.groupBy(\"produto\", \"id_loja\", \"ano_mes\") \\\n",
    "                  .agg(F.sum(\"qtde\").alias(\"qtde\"))\n",
    "\n",
    "df_agg = df_agg.withColumn(\n",
    "    \"ano_mes\",\n",
    "    F.to_date(F.concat_ws(\"-\", F.col(\"ano_mes\"), F.lit(\"01\")), \"yyyy-MM-dd\")\n",
    ")\n",
    "\n",
    "df_agg = df_agg.filter(F.col(\"id_loja\").isNotNull() & (F.col(\"qtde\") > 0))\n",
    "df_agg = df_agg.repartition(\"produto\", \"id_loja\")\n",
    "\n",
    "# =========================\n",
    "# Fun√ß√£o de forecast otimizada\n",
    "# =========================\n",
    "def forecast_3meses(pdf):\n",
    "    produto = pdf['produto'].iloc[0]\n",
    "    loja = pdf['id_loja'].iloc[0]\n",
    "    pdf = pdf.sort_values('ano_mes').copy()\n",
    "    pdf['ano_mes'] = pd.to_datetime(pdf['ano_mes'])\n",
    "    \n",
    "    # Se hist√≥rico insuficiente ou vendas zeradas: usar m√©dia m√≥vel\n",
    "    if len(pdf) < 3 or pdf['qtde'].sum() == 0:\n",
    "        ma_pred = pdf['qtde'].mean() * 3 if len(pdf) > 0 else 0\n",
    "        return pd.DataFrame({\n",
    "            'produto':[produto],\n",
    "            'id_loja':[loja],\n",
    "            'rf':[0],\n",
    "            'xgb':[0],\n",
    "            'lgb':[0],\n",
    "            'ma':[ma_pred]\n",
    "        })\n",
    "    \n",
    "    # Features de tempo\n",
    "    pdf['ano'] = pdf['ano_mes'].dt.year\n",
    "    pdf['mes'] = pdf['ano_mes'].dt.month\n",
    "    X = pdf[['ano','mes']]\n",
    "    y = pdf['qtde'].values\n",
    "    \n",
    "    # Treinar modelos\n",
    "    rf_model = RandomForestRegressor(n_estimators=5, random_state=42)\n",
    "    rf_model.fit(X, y)\n",
    "    xgb_model = xgb.XGBRegressor(n_estimators=5, n_jobs=-1, random_state=42)\n",
    "    xgb_model.fit(X, y)\n",
    "    lgb_model = lgb.LGBMRegressor(n_estimators=5, n_jobs=-1, random_state=42)\n",
    "    lgb_model.fit(X, y)\n",
    "    \n",
    "    # Pr√≥ximos 3 meses\n",
    "    last_date = pdf['ano_mes'].max()\n",
    "    future_dates = pd.date_range(start=last_date + pd.offsets.MonthBegin(1), periods=3, freq='MS')\n",
    "    future_df = pd.DataFrame({'ano': future_dates.year, 'mes': future_dates.month})\n",
    "    \n",
    "    # Previs√µes\n",
    "    rf_pred = np.clip(rf_model.predict(future_df), 0, None).sum()\n",
    "    xgb_pred = np.clip(xgb_model.predict(future_df), 0, None).sum()\n",
    "    lgb_pred = np.clip(lgb_model.predict(future_df), 0, None).sum()\n",
    "    ma_pred = pdf['qtde'].rolling(3, min_periods=1).mean().iloc[-1] * 3\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'produto':[produto],\n",
    "        'id_loja':[loja],\n",
    "        'rf':[rf_pred],\n",
    "        'xgb':[xgb_pred],\n",
    "        'lgb':[lgb_pred],\n",
    "        'ma':[ma_pred]\n",
    "    })\n",
    "\n",
    "# =========================\n",
    "# Schema\n",
    "# =========================\n",
    "# =========================\n",
    "# Schema corrigido\n",
    "# =========================\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"produto\", StringType()),   # produto como string\n",
    "    StructField(\"id_loja\", StringType()),   # id_loja como string\n",
    "    StructField(\"rf\", DoubleType()),\n",
    "    StructField(\"xgb\", DoubleType()),\n",
    "    StructField(\"lgb\", DoubleType()),\n",
    "    StructField(\"ma\", DoubleType())\n",
    "])\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Aplicar forecast em paralelo\n",
    "# =========================\n",
    "df_forecast = df_agg.groupBy(\"produto\",\"id_loja\") \\\n",
    "                    .applyInPandas(forecast_3meses, schema=schema)\n",
    "\n",
    "# =========================\n",
    "# Mostrar resultado r√°pido\n",
    "# =========================\n",
    "df_forecast.show(5, truncate=False)\n",
    "\n",
    "# =========================\n",
    "# Salvar em Delta\n",
    "# =========================\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS ted_dev.dev_andre_silva\")\n",
    "df_forecast.write.mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .saveAsTable(\"ted_dev.dev_andre_silva.forecast_loja_3meses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27fddecc-c123-455d-8e8b-3488361420d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- =========================\n",
    "-- Exemplo Sazonalidade\n",
    "-- =========================\n",
    "SELECT\n",
    "    data_de_venda,\n",
    "    SUM(qtde) AS qtde_mensal\n",
    "FROM ted_dev.dbt_acroccia_aw_marts.fato_pedidos_2\n",
    "WHERE produto = 'AWC Logo Cap'\n",
    "  AND id_loja = '1002'\n",
    "GROUP BY data_de_venda\n",
    "ORDER BY data_de_venda;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3d12be5-e28e-486a-b998-13a77fd70e26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def forecast_3meses_com_metrica(pdf):\n",
    "    produto = pdf['produto'].iloc[0]\n",
    "    loja = pdf['id_loja'].iloc[0]\n",
    "    pdf = pdf.sort_values('ano_mes').copy()\n",
    "    pdf['ano_mes'] = pd.to_datetime(pdf['ano_mes'])\n",
    "\n",
    "    if len(pdf) < 6 or pdf['qtde'].sum() == 0:\n",
    "        ma_pred = pdf['qtde'].mean() * 3 if len(pdf) > 0 else 0\n",
    "        return pd.DataFrame({\n",
    "            'produto':[produto],\n",
    "            'id_loja':[loja],\n",
    "            'rf':[0], 'xgb':[0], 'lgb':[0], 'ma':[ma_pred],\n",
    "            'rf_mae':[None], 'rf_rmse':[None], 'rf_r2':[None],\n",
    "            'xgb_mae':[None], 'xgb_rmse':[None], 'xgb_r2':[None],\n",
    "            'lgb_mae':[None], 'lgb_rmse':[None], 'lgb_r2':[None]\n",
    "        })\n",
    "\n",
    "    pdf['ano'] = pdf['ano_mes'].dt.year\n",
    "    pdf['mes'] = pdf['ano_mes'].dt.month\n",
    "    X = pdf[['ano','mes']]\n",
    "    y = pdf['qtde'].values\n",
    "\n",
    "    # Separar treino e teste (√∫ltimos 3 meses como teste)\n",
    "    X_train, X_test = X[:-3], X[-3:]\n",
    "    y_train, y_test = y[:-3], y[-3:]\n",
    "\n",
    "    # Treinar modelos\n",
    "    rf_model = RandomForestRegressor(n_estimators=5, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    xgb_model = xgb.XGBRegressor(n_estimators=5, n_jobs=-1, random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    lgb_model = lgb.LGBMRegressor(n_estimators=5, n_jobs=-1, random_state=42)\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Previs√µes nos 3 meses de teste\n",
    "    rf_test_pred = rf_model.predict(X_test)\n",
    "    xgb_test_pred = xgb_model.predict(X_test)\n",
    "    lgb_test_pred = lgb_model.predict(X_test)\n",
    "\n",
    "    # M√©tricas\n",
    "    rf_mae = mean_absolute_error(y_test, rf_test_pred)\n",
    "    rf_rmse = mean_squared_error(y_test, rf_test_pred, squared=False)\n",
    "    rf_r2 = r2_score(y_test, rf_test_pred)\n",
    "\n",
    "    xgb_mae = mean_absolute_error(y_test, xgb_test_pred)\n",
    "    xgb_rmse = mean_squared_error(y_test, xgb_test_pred, squared=False)\n",
    "    xgb_r2 = r2_score(y_test, xgb_test_pred)\n",
    "\n",
    "    lgb_mae = mean_absolute_error(y_test, lgb_test_pred)\n",
    "    lgb_rmse = mean_squared_error(y_test, lgb_test_pred, squared=False)\n",
    "    lgb_r2 = r2_score(y_test, lgb_test_pred)\n",
    "\n",
    "    # Previs√£o para os pr√≥ximos 3 meses\n",
    "    last_date = pdf['ano_mes'].max()\n",
    "    future_dates = pd.date_range(start=last_date + pd.offsets.MonthBegin(1), periods=3, freq='MS')\n",
    "    future_df = pd.DataFrame({'ano': future_dates.year, 'mes': future_dates.month})\n",
    "\n",
    "    rf_pred = np.clip(rf_model.predict(future_df), 0, None).sum()\n",
    "    xgb_pred = np.clip(xgb_model.predict(future_df), 0, None).sum()\n",
    "    lgb_pred = np.clip(lgb_model.predict(future_df), 0, None).sum()\n",
    "    ma_pred = pdf['qtde'].rolling(3, min_periods=1).mean().iloc[-1] * 3\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'produto':[produto],\n",
    "        'id_loja':[loja],\n",
    "        'rf':[rf_pred], 'xgb':[xgb_pred], 'lgb':[lgb_pred], 'ma':[ma_pred],\n",
    "        'rf_mae':[rf_mae], 'rf_rmse':[rf_rmse], 'rf_r2':[rf_r2],\n",
    "        'xgb_mae':[xgb_mae], 'xgb_rmse':[xgb_rmse], 'xgb_r2':[xgb_r2],\n",
    "        'lgb_mae':[lgb_mae], 'lgb_rmse':[lgb_rmse], 'lgb_r2':[lgb_r2]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10934a60-dad7-45dc-b3de-8a102e522c3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# ETAPA 2 - ESTUDO DOS MODELOS E AN√ÅLISE POR M√âTRICA\n",
    "# =========================\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# Carregar e preparar dados\n",
    "# =========================\n",
    "df_vendas = spark.table(\"ted_dev.dbt_acroccia_aw_marts.fato_pedidos_2\")\n",
    "\n",
    "df_vendas = df_vendas.withColumn(\"ano_mes\", F.date_format(\"data_de_venda\", \"yyyy-MM\"))\n",
    "df_agg = df_vendas.groupBy(\"produto\", \"id_loja\", \"ano_mes\") \\\n",
    "                  .agg(F.sum(\"qtde\").alias(\"qtde\"))\n",
    "\n",
    "df_agg = df_agg.withColumn(\n",
    "    \"ano_mes\",\n",
    "    F.to_date(F.concat_ws(\"-\", F.col(\"ano_mes\"), F.lit(\"01\")), \"yyyy-MM-dd\")\n",
    ")\n",
    "\n",
    "df_agg = df_agg.filter(F.col(\"id_loja\").isNotNull() & (F.col(\"qtde\") > 0))\n",
    "df_agg = df_agg.repartition(\"produto\", \"id_loja\")\n",
    "\n",
    "# =========================\n",
    "# Fun√ß√£o de forecast com m√©tricas\n",
    "# =========================\n",
    "def forecast_3meses_com_metrica(pdf):\n",
    "    produto = pdf['produto'].iloc[0]\n",
    "    loja = pdf['id_loja'].iloc[0]\n",
    "    pdf = pdf.sort_values('ano_mes').copy()\n",
    "    pdf['ano_mes'] = pd.to_datetime(pdf['ano_mes'])\n",
    "\n",
    "    if len(pdf) < 6 or pdf['qtde'].sum() == 0:\n",
    "        ma_pred = pdf['qtde'].mean() * 3 if len(pdf) > 0 else 0\n",
    "        return pd.DataFrame({\n",
    "            'produto':[produto],\n",
    "            'id_loja':[loja],\n",
    "            'rf':[0], 'xgb':[0], 'lgb':[0], 'ma':[ma_pred],\n",
    "            'rf_mae':[None], 'rf_rmse':[None], 'rf_r2':[None],\n",
    "            'xgb_mae':[None], 'xgb_rmse':[None], 'xgb_r2':[None],\n",
    "            'lgb_mae':[None], 'lgb_rmse':[None], 'lgb_r2':[None]\n",
    "        })\n",
    "\n",
    "    pdf['ano'] = pdf['ano_mes'].dt.year\n",
    "    pdf['mes'] = pdf['ano_mes'].dt.month\n",
    "    X = pdf[['ano','mes']]\n",
    "    y = pdf['qtde'].values\n",
    "\n",
    "    X_train, X_test = X[:-3], X[-3:]\n",
    "    y_train, y_test = y[:-3], y[-3:]\n",
    "\n",
    "    rf_model = RandomForestRegressor(n_estimators=5, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    xgb_model = xgb.XGBRegressor(n_estimators=5, n_jobs=-1, random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    lgb_model = lgb.LGBMRegressor(n_estimators=5, n_jobs=-1, random_state=42)\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "\n",
    "    rf_test_pred = rf_model.predict(X_test)\n",
    "    xgb_test_pred = xgb_model.predict(X_test)\n",
    "    lgb_test_pred = lgb_model.predict(X_test)\n",
    "\n",
    "    rf_mae = mean_absolute_error(y_test, rf_test_pred)\n",
    "    rf_rmse = mean_squared_error(y_test, rf_test_pred, squared=False)\n",
    "    rf_r2 = r2_score(y_test, rf_test_pred)\n",
    "\n",
    "    xgb_mae = mean_absolute_error(y_test, xgb_test_pred)\n",
    "    xgb_rmse = mean_squared_error(y_test, xgb_test_pred, squared=False)\n",
    "    xgb_r2 = r2_score(y_test, xgb_test_pred)\n",
    "\n",
    "    lgb_mae = mean_absolute_error(y_test, lgb_test_pred)\n",
    "    lgb_rmse = mean_squared_error(y_test, lgb_test_pred, squared=False)\n",
    "    lgb_r2 = r2_score(y_test, lgb_test_pred)\n",
    "\n",
    "    last_date = pdf['ano_mes'].max()\n",
    "    future_dates = pd.date_range(start=last_date + pd.offsets.MonthBegin(1), periods=3, freq='MS')\n",
    "    future_df = pd.DataFrame({'ano': future_dates.year, 'mes': future_dates.month})\n",
    "\n",
    "    rf_pred = np.clip(rf_model.predict(future_df), 0, None).sum()\n",
    "    xgb_pred = np.clip(xgb_model.predict(future_df), 0, None).sum()\n",
    "    lgb_pred = np.clip(lgb_model.predict(future_df), 0, None).sum()\n",
    "    ma_pred = pdf['qtde'].rolling(3, min_periods=1).mean().iloc[-1] * 3\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'produto':[produto],\n",
    "        'id_loja':[loja],\n",
    "        'rf':[rf_pred], 'xgb':[xgb_pred], 'lgb':[lgb_pred], 'ma':[ma_pred],\n",
    "        'rf_mae':[rf_mae], 'rf_rmse':[rf_rmse], 'rf_r2':[rf_r2],\n",
    "        'xgb_mae':[xgb_mae], 'xgb_rmse':[xgb_rmse], 'xgb_r2':[xgb_r2],\n",
    "        'lgb_mae':[lgb_mae], 'lgb_rmse':[lgb_rmse], 'lgb_r2':[lgb_r2]\n",
    "    })\n",
    "\n",
    "# =========================\n",
    "# Schema\n",
    "# =========================\n",
    "schema = StructType([\n",
    "    StructField(\"produto\", StringType()),\n",
    "    StructField(\"id_loja\", StringType()),\n",
    "    StructField(\"rf\", DoubleType()),\n",
    "    StructField(\"xgb\", DoubleType()),\n",
    "    StructField(\"lgb\", DoubleType()),\n",
    "    StructField(\"ma\", DoubleType()),\n",
    "    StructField(\"rf_mae\", DoubleType()),\n",
    "    StructField(\"rf_rmse\", DoubleType()),\n",
    "    StructField(\"rf_r2\", DoubleType()),\n",
    "    StructField(\"xgb_mae\", DoubleType()),\n",
    "    StructField(\"xgb_rmse\", DoubleType()),\n",
    "    StructField(\"xgb_r2\", DoubleType()),\n",
    "    StructField(\"lgb_mae\", DoubleType()),\n",
    "    StructField(\"lgb_rmse\", DoubleType()),\n",
    "    StructField(\"lgb_r2\", DoubleType())\n",
    "])\n",
    "\n",
    "# =========================\n",
    "# Aplicar forecast e mostrar resultado\n",
    "# =========================\n",
    "df_forecast = df_agg.groupBy(\"produto\",\"id_loja\") \\\n",
    "                    .applyInPandas(forecast_3meses_com_metrica, schema=schema)\n",
    "\n",
    "df_forecast.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31f1b5cc-6e8a-49d9-8004-66b98e25fac3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03d46bff-adb8-4959-b335-2d06586eb7b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# ============================================\n",
    "# ETAPA 3 - Carregar a tabela fato\n",
    "# ============================================\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "\n",
    "# Ler tabela do Databricks (Spark ‚Üí Pandas)\n",
    "df = spark.table(\"ted_dev.dbt_acroccia_aw_marts.fato_pedidos_2\").toPandas()\n",
    "\n",
    "# Converter datas\n",
    "df[\"data_de_venda\"] = pd.to_datetime(df[\"data_de_venda\"])\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0720b8df-3daf-4c77-a5fc-f48f22ce0765",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "# ============================================\n",
    "# ETAPA 3 - Crescimento por Grupo (Prov√≠ncias EUA x Pa√≠ses resto do mundo)\n",
    "# ============================================\n",
    "from prophet import Prophet\n",
    "\n",
    "# Criar coluna grupo (Provincia = EUA, Pais = resto do mundo)\n",
    "df[\"grupo\"] = df[\"pais\"].apply(lambda x: \"Provincia\" if x == \"United States\" else \"Pais\")\n",
    "\n",
    "# Agregar mensalmente por grupo\n",
    "df_group = df.groupby(\n",
    "    [df[\"data_de_venda\"].dt.to_period(\"M\"), \"grupo\"]\n",
    ")[\"qtde\"].sum().reset_index()\n",
    "\n",
    "df_group[\"ano_mes\"] = df_group[\"data_de_venda\"].dt.to_timestamp()\n",
    "\n",
    "# Fun√ß√£o para rodar Prophet em cada grupo\n",
    "def forecast_group(grupo_nome):\n",
    "    serie = df_group[df_group[\"grupo\"] == grupo_nome][[\"ano_mes\", \"qtde\"]].rename(\n",
    "        columns={\"ano_mes\": \"ds\", \"qtde\": \"y\"}\n",
    "    )\n",
    "\n",
    "    m = Prophet(yearly_seasonality=True, daily_seasonality=False)\n",
    "    m.fit(serie)\n",
    "\n",
    "    future = m.make_future_dataframe(periods=3, freq=\"M\")\n",
    "    forecast = m.predict(future)\n",
    "\n",
    "    # Previs√£o total dos pr√≥ximos 3 meses\n",
    "    total_previsto = forecast.tail(3)[\"yhat\"].sum()\n",
    "    return total_previsto, forecast, m\n",
    "\n",
    "# Rodar para \"Provincia\" (EUA) e \"Pais\" (resto do mundo)\n",
    "prev_provincia, forecast_provincia, m_provincia = forecast_group(\"Provincia\")\n",
    "prev_pais, forecast_pais, m_pais = forecast_group(\"Pais\")\n",
    "\n",
    "print(\"Demanda prevista - Pr√≥ximos 3 meses:\")\n",
    "print(f\"Provincias (EUA): {prev_provincia:.0f}\")\n",
    "print(f\"Pa√≠ses (Resto do mundo): {prev_pais:.0f}\")\n",
    "\n",
    "# Comparar quem cresceu mais\n",
    "if prev_provincia > prev_pais:\n",
    "    print(\"üëâ O grupo Provincias (EUA) apresentou mais crescimento.\")\n",
    "else:\n",
    "    print(\"üëâ O grupo Pa√≠ses (resto do mundo) apresentou mais crescimento.\")\n",
    "\n",
    "# (Opcional) Gr√°ficos\n",
    "fig1 = m_provincia.plot(forecast_provincia)\n",
    "fig2 = m_pais.plot(forecast_pais)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c25150d9-edd4-48bb-b8ef-95b8fe6c3677",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "# ============================================\n",
    "# ETAPA 4 - Estimativa de z√≠peres (Gloves)\n",
    "# ============================================\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "\n",
    "# Ler tabela do Databricks (Spark ‚Üí Pandas)\n",
    "df = spark.table(\"ted_dev.dbt_acroccia_aw_marts.fato_pedidos_2\").toPandas()\n",
    "\n",
    "# Converter datas\n",
    "df[\"data_de_venda\"] = pd.to_datetime(df[\"data_de_venda\"])\n",
    "\n",
    "# Filtrar apenas luvas\n",
    "df_gloves = df[df[\"produto\"].str.contains(\"Gloves\", case=False, na=False)]\n",
    "\n",
    "# Agregar mensalmente\n",
    "serie_gloves = df_gloves.groupby(\n",
    "    df_gloves[\"data_de_venda\"].dt.to_period(\"M\")\n",
    ")[\"qtde\"].sum().reset_index()\n",
    "\n",
    "serie_gloves[\"ano_mes\"] = serie_gloves[\"data_de_venda\"].dt.to_timestamp()\n",
    "serie_gloves = serie_gloves.rename(columns={\"ano_mes\": \"ds\", \"qtde\": \"y\"})\n",
    "\n",
    "# Ajustar modelo Prophet\n",
    "m_gloves = Prophet(yearly_seasonality=True)\n",
    "m_gloves.fit(serie_gloves)\n",
    "\n",
    "# Previs√£o 3 meses\n",
    "future_gloves = m_gloves.make_future_dataframe(periods=3, freq=\"M\")\n",
    "forecast_gloves = m_gloves.predict(future_gloves)\n",
    "\n",
    "# Calcular total previsto\n",
    "prev_gloves = forecast_gloves.tail(3)[\"yhat\"].sum()\n",
    "\n",
    "# Estimativa de z√≠peres (2 por par)\n",
    "zippers_needed = int(prev_gloves * 2)\n",
    "print(\"Z√≠peres necess√°rios (pr√≥ximos 3 meses):\", zippers_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb7ad40e-2ae0-4aeb-95f8-b6a70e27b96a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "WITH previsao_luvas AS (\n",
    "    SELECT \n",
    "        produto,\n",
    "        id_loja,\n",
    "        rf, xgb, lgb, ma,\n",
    "        (rf + xgb + lgb + ma)/4 AS media_modelos\n",
    "    FROM ted_dev.dev_andre_silva.forecast_loja_3meses \n",
    "    WHERE LOWER(produto) LIKE '%gloves%'\n",
    ")\n",
    "SELECT\n",
    "    SUM(media_modelos) * 2 AS ziperes_necessarios_prox_3_meses\n",
    "FROM previsao_luvas;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0da4bbc2-923d-4ab2-9187-f6170a0bffc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "    SELECT \n",
    "        produto,\n",
    "        id_loja,\n",
    "        rf, xgb, lgb, ma,\n",
    "        (rf + xgb + lgb + ma)/4 AS media_modelos\n",
    "    FROM ted_dev.dev_andre_silva.forecast_loja_3meses \n",
    "    WHERE LOWER(produto) LIKE '%gloves%'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1173309c-b36e-4da0-9159-9672e04dba59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "    YEAR(data_de_venda) AS ano,\n",
    "    MONTH(data_de_venda) AS mes,\n",
    "    SUM(qtde) AS total_luvas_vendidas\n",
    "FROM ted_dev.dbt_acroccia_aw_marts.fato_pedidos_2\n",
    "WHERE LOWER(produto) LIKE '%glove%'\n",
    "GROUP BY YEAR(data_de_venda), MONTH(data_de_venda)\n",
    "ORDER BY ano, mes;\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0603ae93-29d1-46f3-a3ec-6f5aeaf6b7a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5697862893036505,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "CH5",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
